{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several techniques are deployed to classify EMG\n",
    "data such as artificial neural networks (ANN), Bayesian classifier (BC), fuzzy logic (FL), multilayer\n",
    "perceptron (MLP), support vector machines (SVM), linear discriminant analysis (LDA), hidden Markov\n",
    "models (HMM) and K-nearest neighbor (KNN). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# Import libraries\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Formatting\n",
    "###### Include labels in individual csv folders\n",
    "0: rest\n",
    "1: fist\n",
    "2: open palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I currently have 3 folders with 14 files each  (each file 1000 samples long)\n",
    "# I want to merge them all into one file (they must be properly labeled first)\n",
    "\n",
    "\n",
    "#\"\"\" I coudl make multiple paths to the original csv files and loop through so that I do not have to manually edit the path \n",
    "#I can do the same for the 'label' input \"\"\"\n",
    "#\n",
    "#path = '/home/cybathlon/catkin_ws/src/bagFiles/rest' # all these must be labeled 0\n",
    "#all_files = glob.glob(path + \"/*.csv\") #all files ending in csv\n",
    "#\n",
    "#onefile = []\n",
    "#\n",
    "#for filename in all_files: #read through all csv files and append them to each other\n",
    "#    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#    onefile.append(df)\n",
    "#    \n",
    "##TODO: modify the input of 'label' column\n",
    "#concatdf = pd.concat(onefile, axis=0, ignore_index=True) #concatenate all files into a full dataframe\n",
    "#concatdf['label'] = '0' #add column label of zeros\n",
    "#concatdf.to_csv(path + '0full.csv', index=False)#save df to csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Join all files into one for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that I have 3 csv files labeled, I can concatenate them to have one big file with all my data\n",
    "# reuse code above\n",
    "\n",
    "#path = '/home/cybathlon/catkin_ws/src/bagFiles'\n",
    "#all_files = glob.glob(path + \"/*.csv\") #all files ending in csv\n",
    "#\n",
    "#eachfile = []\n",
    "#\n",
    "#for filename in all_files: #read through all csv files and append them to each other\n",
    "#    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#    eachfile.append(df)\n",
    "#\n",
    "#fulldf = pd.concat(eachfile, axis=0, ignore_index=True)\n",
    "#fulldf.to_csv(path + 'full_csv.csv', index=False) #save df to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the data correctly set and split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set\n",
    "# Import data set\n",
    "df = pd.read_csv(\"/home/cybathlon/catkin_ws/src/bagFiles/bagFilesfull_csv.csv\")\n",
    "#df = pd.read_csv(r\"C:\\Users\\Paula\\Desktop\\9weekproject\\gitwork\\EMGMyoRosClassification\\bagFiles\\full_csv.csv\")\n",
    "x = df[[\"EMG0\", \"EMG1\", \"EMG2\", \"EMG3\", \"EMG4\", \"EMG5\", \"EMG6\", \"EMG7\"]].values\n",
    "y = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test set using 80% train 20% test\n",
    "x_train , x_test , y_train , y_test = train_test_split(x , y , shuffle=True, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # define scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[ 75.95016204  86.99583333  92.65518519 198.70185185 306.37851852\n",
      " 101.19851852 149.56972222  74.53810185]\n",
      "[[ 0.30063111  2.38126717  6.15343404 ...  0.49970343  0.7708874\n",
      "   0.21755642]\n",
      " [ 0.27336278  2.02662084  5.29969901 ...  0.52686013  0.74485056\n",
      "   0.20139552]\n",
      " [ 0.09611865  1.79018995  4.19932941 ...  0.71695705  0.66023085\n",
      "   0.10443011]\n",
      " ...\n",
      " [-0.80373619 -0.99631695 -0.67644624 ... -1.03465023 -0.84990558\n",
      "  -0.86522405]\n",
      " [-0.81737036 -0.97942903 -0.71439002 ... -1.03465023 -0.84990558\n",
      "  -0.88138495]\n",
      " [-0.79010203 -0.87810151 -0.60055868 ... -1.03465023 -0.85641479\n",
      "  -0.88138495]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.fit(x_train)) # fit scaler on the training dataset\n",
    "print(scaler.mean_)\n",
    "print(scaler.transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.35516777  0.4391563  -0.27803656 ...  0.39107662  3.64795766\n",
      "   2.69017452]\n",
      " [ 1.66404754 -0.16880884 -0.29700845 ... -0.27426257  0.15902178\n",
      "   0.45996996]\n",
      " [-0.80373619 -1.18208408 -1.41634994 ... -0.6544564  -0.8694332\n",
      "  -0.88138495]\n",
      " ...\n",
      " [-0.32654044  0.30405294 -0.31598034 ... -0.84455332 -0.84339637\n",
      "  -0.70361502]\n",
      " [ 2.27758493 -0.0505934  -0.27803656 ...  0.21455806  1.43482669\n",
      "   2.07606022]\n",
      " [-0.72193121 -1.03009279 -0.94205269 ... -0.72234816 -0.83688716\n",
      "  -0.86522405]]\n"
     ]
    }
   ],
   "source": [
    "# transform both datasets \n",
    "x_train = scaler.transform(x_train) #x_train_scaled = scaler.fit(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line Model (Without Optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=7000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel = 'poly', cache_size=7000) #create svm classifier with polynomial kernel (maybe try with rbg)\n",
    "clf.fit(x_train,y_train) #train the model using training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(x_train)\n",
    "y_pred_test = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3566\n",
      "          1       1.00      1.00      1.00      3597\n",
      "          2       1.00      1.00      1.00      3637\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9980555555555556)\n"
     ]
    }
   ],
   "source": [
    "#Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Precision:', 0.9980555555555556)\n",
      "('Recall:', 0.9980555555555556)\n"
     ]
    }
   ],
   "source": [
    "#Model Precision: what percentage of positive tuples are labeled as such?\n",
    "#Model Recall: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_test, average = 'micro'))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred_test, average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] kernel=poly, C=0.1, gamma=1 .....................................\n",
      "[CV] kernel=poly, C=0.1, gamma=1 .....................................\n",
      "[CV] kernel=poly, C=0.1, gamma=1 .....................................\n",
      "[CV] kernel=poly, C=0.1, gamma=0.1 ...................................\n",
      "[CV] kernel=poly, C=0.1, gamma=0.1 ...................................\n",
      "[CV] kernel=poly, C=0.1, gamma=0.1 ...................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=1, score=0.999583333333, total=   0.5s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.01 ..................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=1, score=0.998888811723, total=   0.5s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.01 ..................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=1, score=0.999583362267, total=   0.5s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.01 ..................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.1, score=0.992361111111, total=   5.8s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.001 .................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.1, score=0.993542115131, total=   5.8s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.001 .................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.1, score=0.994374609348, total=   6.0s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.001 .................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.01, score=0.433363428016, total=  50.1s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.0001 ................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.01, score=0.434275397542, total=  51.7s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.0001 ................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.01, score=0.435833333333, total=  52.5s\n",
      "[CV] kernel=poly, C=0.1, gamma=0.0001 ................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.001, score=0.33412042503, total=  50.7s\n",
      "[CV] kernel=poly, C=1, gamma=1 .......................................\n",
      "[CV] .. kernel=poly, C=1, gamma=1, score=0.999444483022, total=   0.4s\n",
      "[CV] kernel=poly, C=1, gamma=1 .......................................\n",
      "[CV] .. kernel=poly, C=1, gamma=1, score=0.999444444444, total=   0.4s\n",
      "[CV] kernel=poly, C=1, gamma=1 .......................................\n",
      "[CV] .. kernel=poly, C=1, gamma=1, score=0.999166608792, total=   0.4s\n",
      "[CV] kernel=poly, C=1, gamma=0.1 .....................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.001, score=0.33414346226, total=  52.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.1 .....................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.001, score=0.334097222222, total=  52.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.1 .....................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.1, score=0.996944656621, total=   2.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.01 ....................................\n",
      "[CV] ...... kernel=poly, C=1, gamma=0.1, score=0.996875, total=   2.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.01 ....................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.1, score=0.997222029308, total=   1.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.01 ....................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.01, score=0.927222222222, total=  36.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.001 ...................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.01, score=0.939240330533, total=  36.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  2.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=poly, C=1, gamma=0.01, score=0.91221612612, total=  36.7s\n",
      "[CV] kernel=poly, C=1, gamma=0.001 ...................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.0001, score=0.33414346226, total=  48.8s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001 ..................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.0001, score=0.334097222222, total=  49.5s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001 ..................................\n",
      "[CV]  kernel=poly, C=0.1, gamma=0.0001, score=0.33412042503, total=  50.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001 ..................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, score=0.33414346226, total=  53.0s\n",
      "[CV] kernel=poly, C=10, gamma=1 ......................................\n",
      "[CV] . kernel=poly, C=10, gamma=1, score=0.999236164155, total=   0.4s\n",
      "[CV] kernel=poly, C=10, gamma=1 ......................................\n",
      "[CV] . kernel=poly, C=10, gamma=1, score=0.999513888889, total=   0.4s\n",
      "[CV] kernel=poly, C=10, gamma=1 ......................................\n",
      "[CV] .. kernel=poly, C=10, gamma=1, score=0.99895826099, total=   0.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.1 ....................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, score=0.334097222222, total=  53.9s\n",
      "[CV] kernel=poly, C=10, gamma=0.1 ....................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.1, score=0.998819526422, total=   0.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.1 ....................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.1, score=0.998888888889, total=   0.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.01 ...................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, score=0.33412042503, total=  54.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.01 ...................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.1, score=0.998541565386, total=   0.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.01 ...................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, score=0.33414346226, total=  53.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.001 ..................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, score=0.334097222222, total=  51.9s\n",
      "[CV] kernel=poly, C=10, gamma=0.001 ..................................\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, score=0.33412042503, total=  50.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.001 ..................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.01, score=0.975973890702, total=  16.9s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001 .................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.01, score=0.977708333333, total=  17.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001 .................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.01, score=0.980832002222, total=  17.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001 .................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, score=0.335879452816, total=  51.0s\n",
      "[CV] kernel=poly, C=100, gamma=1 .....................................\n",
      "[CV]  kernel=poly, C=100, gamma=1, score=0.999236164155, total=   0.4s\n",
      "[CV] kernel=poly, C=100, gamma=1 .....................................\n",
      "[CV]  kernel=poly, C=100, gamma=1, score=0.999097222222, total=   0.3s\n",
      "[CV] kernel=poly, C=100, gamma=1 .....................................\n",
      "[CV] . kernel=poly, C=100, gamma=1, score=0.99895826099, total=   0.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.1 ...................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, score=0.337083333333, total=  50.7s\n",
      "[CV] kernel=poly, C=100, gamma=0.1 ...................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.1, score=0.999583362267, total=   0.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.1 ...................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.1, score=0.999583333333, total=   0.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.01 ..................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, score=0.336412250851, total=  51.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.01 ..................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.1, score=0.998888811723, total=   0.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.01 ..................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.01, score=0.993542115131, total=   4.8s\n",
      "[CV] kernel=poly, C=100, gamma=0.001 .................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.01, score=0.994374609348, total=   5.0s\n",
      "[CV] kernel=poly, C=100, gamma=0.001 .................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.01, score=0.992361111111, total=   5.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.001 .................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, score=0.33414346226, total=  51.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001 ................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, score=0.334097222222, total=  51.0s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001 ................................\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, score=0.33412042503, total=  50.8s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001 ................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, score=0.434275397542, total=  51.3s\n",
      "[CV] kernel=poly, C=1000, gamma=1 ....................................\n",
      "[CV]  kernel=poly, C=1000, gamma=1, score=0.999236164155, total=   0.4s\n",
      "[CV] kernel=poly, C=1000, gamma=1 ....................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, score=0.435833333333, total=  51.3s\n",
      "[CV] kernel=poly, C=1000, gamma=1 ....................................\n",
      "[CV]  kernel=poly, C=1000, gamma=1, score=0.999097222222, total=   0.3s\n",
      "[CV] kernel=poly, C=1000, gamma=0.1 ..................................\n",
      "[CV]  kernel=poly, C=1000, gamma=1, score=0.99895826099, total=   0.4s\n",
      "[CV] kernel=poly, C=1000, gamma=0.1 ..................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, score=0.433363428016, total=  51.7s\n",
      "[CV] kernel=poly, C=1000, gamma=0.1 ..................................\n",
      "[CV]  kernel=poly, C=1000, gamma=0.1, score=0.999444483022, total=   0.4s\n",
      "[CV] kernel=poly, C=1000, gamma=0.01 .................................\n",
      "[CV]  kernel=poly, C=1000, gamma=0.1, score=0.999444444444, total=   0.4s\n",
      "[CV] kernel=poly, C=1000, gamma=0.01 .................................\n",
      "[CV]  kernel=poly, C=1000, gamma=0.1, score=0.999166608792, total=   0.3s\n",
      "[CV] kernel=poly, C=1000, gamma=0.01 .................................\n",
      "[CV]  kernel=poly, C=1000, gamma=0.01, score=0.996944656621, total=   1.7s\n",
      "[CV] kernel=poly, C=1000, gamma=0.001 ................................\n",
      "[CV]  kernel=poly, C=1000, gamma=0.01, score=0.997222029308, total=   1.6s\n",
      "[CV] kernel=poly, C=1000, gamma=0.001 ................................\n",
      "[CV] .. kernel=poly, C=1000, gamma=0.01, score=0.996875, total=   1.8s\n",
      "[CV] kernel=poly, C=1000, gamma=0.001 ................................\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, score=0.33414346226, total=  52.0s\n",
      "[CV] kernel=poly, C=1000, gamma=0.0001 ...............................\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, score=0.33412042503, total=  51.8s\n",
      "[CV] kernel=poly, C=1000, gamma=0.0001 ...............................\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, score=0.334097222222, total=  53.4s\n",
      "[CV] kernel=poly, C=1000, gamma=0.0001 ...............................\n",
      "[CV]  kernel=poly, C=1000, gamma=0.001, score=0.939240330533, total=  35.5s\n",
      "[CV]  kernel=poly, C=1000, gamma=0.001, score=0.927222222222, total=  36.5s\n",
      "[CV]  kernel=poly, C=1000, gamma=0.001, score=0.91221612612, total=  36.8s\n",
      "[CV]  kernel=poly, C=1000, gamma=0.0001, score=0.334097222222, total=  44.6s\n",
      "[CV]  kernel=poly, C=1000, gamma=0.0001, score=0.33414346226, total=  45.9s\n",
      "[CV]  kernel=poly, C=1000, gamma=0.0001, score=0.33412042503, total=  44.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'kernel': ['poly'], 'C': [0.1, 1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parameter Tuning:\n",
    "#defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['poly']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "#fitting the model for grid search with scaled dataset\n",
    "grid.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'C': 0.1, 'gamma': 1}\n",
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = grid.best_estimator_\n",
    "model.fit(x_train, y_train) # model includes scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the model\n",
    "y_pred = grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      3566\n",
      "          1       1.00      1.00      1.00      3597\n",
      "          2       1.00      1.00      1.00      3637\n",
      "\n",
      "avg / total       1.00      1.00      1.00     10800\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix : \n",
      "\n",
      "[[3566    0    0]\n",
      " [   2 3595    0]\n",
      " [   0    4 3633]]\n",
      "('\\n\\n Accuracy Score : ', 0.9994444444444445)\n"
     ]
    }
   ],
   "source": [
    "# performance analysis of the model\n",
    "class_rep = classification_report(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(class_rep)\n",
    "print('\\n\\nConfusion Matrix : \\n')\n",
    "print(conf_mat)\n",
    "print('\\n\\n Accuracy Score : ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model persistence\n",
    "import pickle\n",
    "# save the model\n",
    "pickle.dump(model, open(\"svmClassifier1030.pkl\", \"wb\"),protocol =2)\n",
    "# save the scaler\n",
    "pickle.dump(scaler, open('scaler1030.pkl', 'wb'), protocol =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the predicted class vs actual class (0 based indexing)\n",
    "plt.figure(figsize = (15, 10))\n",
    "classes = [i for i in range(1, 4)]\n",
    "svm_df = pd.DataFrame(conf_mat, index = classes, columns = classes)\n",
    "sns.heatmap(svm_df, annot = True)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "knn = KNeighborsClassifier()\n",
    "svc1 = SVC(kernel = 'linear', gamma ='scale')\n",
    "svc2 = SVC(kernel = 'poly', gamma ='scale')\n",
    "svc3 = SVC(kernel = 'rbf', gamma ='scale')\n",
    "\n",
    "model_list = [knn, svc1, svc2, svc3]\n",
    "model_name_list = [\"KNN\", \"linear SVC\", \"poly SVC\", \"rbf SVC\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid\n",
    "x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.02), np.arange(x2_min, x2_max, 0.02))\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features were extracted from the samples by segmenting the signal into 250 ms intervals corresponding to 256 samples in each segment. A single feature was calculated from each segment and the segment window was incremented by 125 ms (128 samples) for the next feature. This scheme ensured that a control command could be generated within 250 ms from the instant the user's intention was given. Three kinds of features were extracted from each segment namely EMG rms value, AR model coefficients and WL.\n",
    "\n",
    "(source: https://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-9-41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Myo Armband already computes the rms value (not sure how)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR models are constructed using a recursive filter. This filter predicts the current value based on the previous output values of the filter. The current value y(t) can be computed as:\n",
    "see math in link above\n",
    "\n",
    "We used the AR model coefficients as the features with a model order of four, which is adequate for modelling EMG signals [42], thus generating four features for each channel of sEMG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third kind of extracted feature was the waveform length, which provided a measure of the waveform complexity in each segment. The waveform length l can be mathematically represented as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used four channels of sEMG data, which therefore provided 24 features per segment. As regards to classification, the LibSVM tool [43] was used in the Matlab environment. LibSVM has an implementation for multi class SVM using one-versus-one strategy and provides a choice of four basic kernels namely linear, polynomial, radial basis function (RBF) and sigmoid. As discussed in [44, 45], RBF is in general a reasonable first choice as it maps the samples nonlinearly and has few numbers of hyperparameters reducing the complexity of model selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
